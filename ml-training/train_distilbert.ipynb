{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "ScamShield ‚Äî DistilBERT Fine-Tuning"
  }
 },
 "cells": [

  {
   "cell_type": "markdown",
   "id": "cell-md-01",
   "metadata": {},
   "source": [
    "# üõ°Ô∏è ScamShield ‚Äî Fine-Tuning DistilBERT for Scam Detection\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What is DistilBERT?\n",
    "\n",
    "**BERT** (Bidirectional Encoder Representations from Transformers) is a large language model created by Google. It was trained on billions of sentences from Wikipedia and Books, so it already understands grammar, context, and language nuance.\n",
    "\n",
    "**DistilBERT** is a *distilled* (compressed) version of BERT ‚Äî it is:\n",
    "- **40% smaller** in size\n",
    "- **60% faster** to run\n",
    "- Retains **97% of BERT's accuracy**\n",
    "\n",
    "This makes it perfect for fine-tuning on a specific task without needing a massive cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß What is Fine-Tuning?\n",
    "\n",
    "DistilBERT is pre-trained on general language. **Fine-tuning** means we continue training it on our specific dataset (scam/spam SMS messages), so it learns to distinguish between:\n",
    "\n",
    "- `0` ‚Üí **Safe** (normal message / ham)\n",
    "- `1` ‚Üí **Scam / Spam**\n",
    "\n",
    "Think of it like hiring a language expert and then giving them a crash course in spotting scams.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Why Transformers for Scam Detection?\n",
    "\n",
    "Traditional ML models (like Naive Bayes or TF-IDF + Logistic Regression) look at individual words. Transformers understand **context**:\n",
    "\n",
    "- `\"Your account is safe\"` ‚Üí normal\n",
    "- `\"Your account will be blocked, click here to keep it safe\"` ‚Üí scam\n",
    "\n",
    "Both sentences contain the word *safe*, but a transformer understands the urgency and call-to-action pattern that makes the second one suspicious.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä What Do the Metrics Mean?\n",
    "\n",
    "| Metric | What it means |\n",
    "|--------|---------------|\n",
    "| **Accuracy** | Out of all predictions, how many were correct? |\n",
    "| **Precision** | Out of all messages flagged as scam, how many actually were scams? |\n",
    "| **Recall** | Out of all actual scams, how many did we catch? |\n",
    "| **F1 Score** | Harmonic mean of Precision and Recall ‚Äî best single metric for imbalanced data |\n",
    "\n",
    "> **Tip:** For scam detection, **Recall** is especially important. Missing a scam (False Negative) is more dangerous than a false alarm.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Before You Start\n",
    "\n",
    "Make sure you have selected a **GPU runtime**:\n",
    "> **Runtime ‚Üí Change runtime type ‚Üí T4 GPU ‚Üí Save**"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-02",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî Install Required Libraries\n",
    "\n",
    "We install the libraries we need. This only needs to be done once per Colab session.\n",
    "\n",
    "- `transformers` ‚Äî provides DistilBERT model and tokenizer\n",
    "- `datasets` ‚Äî easy access to HuggingFace datasets\n",
    "- `evaluate` ‚Äî compute accuracy, F1, precision, recall\n",
    "- `accelerate` ‚Äî makes the Trainer run faster on GPU\n",
    "- `torch` ‚Äî PyTorch deep learning framework (already installed on Colab)"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers>=4.38.0 datasets>=2.18.0 evaluate>=0.4.0 accelerate>=0.27.0 scikit-learn pandas numpy matplotlib seaborn\n",
    "print('‚úÖ All libraries installed!')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-03",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Mount Google Drive\n",
    "\n",
    "We mount Google Drive so we can **save the trained model** directly to your Drive at the end.\n",
    "A popup will ask you to authorize access ‚Äî click Allow."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print('‚úÖ Google Drive mounted at /content/drive')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-04",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî Imports\n",
    "\n",
    "Import all the Python libraries we will use throughout the notebook."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "print(f'‚úÖ PyTorch version: {torch.__version__}')\n",
    "print(f'‚úÖ GPU available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'   GPU name: {torch.cuda.get_device_name(0)}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-05",
   "metadata": {},
   "source": [
    "## Step 4 ‚Äî Dataset 1: SMS Spam Collection\n",
    "\n",
    "This is the classic UCI SMS Spam Collection dataset with **5,574 messages**.\n",
    "\n",
    "- Source: [Justin Markham's PyData tutorial mirror](https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv)\n",
    "- Format: `label` (ham / spam) followed by `text`\n",
    "- We map: `ham ‚Üí 0` (safe), `spam ‚Üí 1` (scam)"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ds1 = 'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv'\n",
    "df1 = pd.read_csv(url_ds1, sep='\\t', header=None, names=['label', 'text'])\n",
    "df1['label'] = df1['label'].map({'ham': 0, 'spam': 1})\n",
    "df1 = df1[['text', 'label']].dropna()\n",
    "\n",
    "print(f'‚úÖ Dataset 1 loaded: {len(df1)} rows')\n",
    "print(f'   Safe (0): {(df1.label == 0).sum()} | Scam (1): {(df1.label == 1).sum()}')\n",
    "df1.head(3)"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-06",
   "metadata": {},
   "source": [
    "## Step 5 ‚Äî Dataset 2: HuggingFace SMS Spam\n",
    "\n",
    "This dataset is hosted on the HuggingFace Hub and contains **5,574 messages** (it is based on the same source but versioned through HuggingFace's `datasets` library).\n",
    "\n",
    "Labels in this dataset are already numeric:\n",
    "- `0` = ham (safe)\n",
    "- `1` = spam (scam)\n",
    "\n",
    "We convert it to a Pandas DataFrame for easy merging."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = load_dataset('sms_spam', split='train')\n",
    "df2 = pd.DataFrame({'text': hf_dataset['sms'], 'label': hf_dataset['label']})\n",
    "# labels: 0 = safe, 1 = scam (already correct)\n",
    "df2 = df2[['text', 'label']].dropna()\n",
    "\n",
    "print(f'‚úÖ Dataset 2 loaded: {len(df2)} rows')\n",
    "print(f'   Safe (0): {(df2.label == 0).sum()} | Scam (1): {(df2.label == 1).sum()}')\n",
    "df2.head(3)"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-07",
   "metadata": {},
   "source": [
    "## Step 6 ‚Äî Dataset 3: Synthetic Phishing Messages\n",
    "\n",
    "Real-world scam datasets often lack **Indian-specific** and modern scam patterns. We generate ~200 synthetic scam messages programmatically to cover:\n",
    "\n",
    "- üè¶ **Bank KYC scams** ‚Äî fake bank alerts demanding KYC updates\n",
    "- üì¶ **Courier scams** ‚Äî fake delivery notifications with phishing links\n",
    "- üíº **Job scams** ‚Äî too-good-to-be-true job offers\n",
    "- üé∞ **Lottery scams** ‚Äî fake prize/lottery winnings\n",
    "- üîê **OTP scams** ‚Äî requests for OTPs to 'verify' accounts\n",
    "\n",
    "All synthetic messages are labeled `1` (scam)."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-07",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_scams = [\n",
    "    # --- Bank KYC Scams ---\n",
    "    \"Dear customer, your SBI account will be suspended. Update KYC immediately at http://sbi-kyc-update.xyz\",\n",
    "    \"HDFC BANK: Your account is on hold due to incomplete KYC. Click here to verify: http://hdfc-kyc.site\",\n",
    "    \"Your bank account has been blocked. Complete your KYC now to avoid permanent deactivation. Call 9876543210.\",\n",
    "    \"ALERT: Your ICICI account will be deactivated in 24 hours. Submit KYC at: http://icicikyc.net\",\n",
    "    \"Attention: Failure to update your Axis Bank KYC will result in account suspension. Verify now: bit.ly/axkyc\",\n",
    "    \"Dear valued customer, PNB requires you to update your KYC. Click the link or visit your nearest branch: http://pnb-kyc.in\",\n",
    "    \"BOB: Your account is frozen. To unfreeze, update KYC details at http://bob-kyc-portal.com within 48 hours.\",\n",
    "    \"Kotak Mahindra Bank: Your KYC is expired. Account will be locked. Update here: http://kotak-kyc.net\",\n",
    "    \"Your YES Bank account needs immediate KYC update. Failure will result in financial penalty. http://yesbank-kyc.in\",\n",
    "    \"Canara Bank: Urgent KYC verification required. Your account access is restricted. Click: http://canarakyc.org\",\n",
    "\n",
    "    # --- Courier Scams ---\n",
    "    \"Your package from Amazon could not be delivered. Pay Rs.45 redelivery fee at: http://amzn-delivery.net\",\n",
    "    \"FedEx: Your shipment AWB#384729 is on hold. Customs clearance payment required. Pay here: http://fedex-clearance.site\",\n",
    "    \"DHL Alert: A package is waiting for you. Confirm your address and pay Rs.99 handling: http://dhl-india.net\",\n",
    "    \"India Post: Your parcel could not be delivered. Reschedule at http://indiapost-tracking.xyz or it will be returned.\",\n",
    "    \"DTDC Courier: Delivery failed attempt. To reschedule, verify your address: http://dtdc-reschedule.in\",\n",
    "    \"Bluedart: Your package is stuck at customs. Pay clearance fee of Rs.150: http://bluedart-customs.com\",\n",
    "    \"Ekart Logistics: Final delivery attempt. Click to reschedule delivery: http://ekart-redeliver.net\",\n",
    "    \"Your parcel #IN9283746 requires verification. Click the link to track and update: http://parceltrack24.site\",\n",
    "    \"Ecomm Express: Your shipment is held at warehouse. Urgent action required: http://ecomm-held.com\",\n",
    "    \"Shadow Fax: Delivery failed. Your item will be returned to sender in 24h. Update now: http://sf-delivery.net\",\n",
    "\n",
    "    # --- Job Scams ---\n",
    "    \"HIRING NOW! Work from home. Earn Rs.50,000/month. No experience needed. WhatsApp 9988776655 to apply today!\",\n",
    "    \"Congratulations! You have been selected for a data entry job. Salary: Rs.40,000/month. Send CV to hr.jobs2024@gmail.com\",\n",
    "    \"Part time job offer. Work 2 hours daily, earn Rs.15,000 weekly. Genuine opportunity. Call 8877665544.\",\n",
    "    \"Urgent hiring for remote customer care executives. No fees. Monthly salary Rs.35,000. Apply: careerzone24.in\",\n",
    "    \"We are hiring for Amazon work from home jobs. Earn Rs.800/hour. Limited slots. Register now: amazon-jobs24.net\",\n",
    "    \"Google is hiring remote workers in India. Salary: Rs.60,000/month. Apply now at: google-remote-jobs.site\",\n",
    "    \"Flipkart Work From Home: Data entry position. Earn Rs.25,000/month. No investment needed. Join via: fl-wfh.in\",\n",
    "    \"You have been shortlisted for a WFH job. Salary Rs.45,000/month. Training fee Rs.500 only. Contact: 9112233445\",\n",
    "    \"Part-time online job. Like and share social media posts. Earn Rs.500/post. Telegram: @earnfromhome2024\",\n",
    "    \"Desperate for a job? We hire everyone! Rs.30,000/month guaranteed. Pay Rs.200 registration. Call 7788990011.\",\n",
    "\n",
    "    # --- Lottery Scams ---\n",
    "    \"Congratulations! Your number has won Rs.50 Lakh in KBC Lucky Draw. To claim, call 9876543210 now!\",\n",
    "    \"You have won an iPhone 15 Pro in our online lucky draw! To claim your prize call: 8899001122\",\n",
    "    \"WINNER NOTIFICATION: Your email was selected in International Lottery. Claim USD $500,000. Reply with your details.\",\n",
    "    \"Lucky Winner! You won Rs.10 Lakh in the Jio lucky draw. Share your bank details to receive the amount.\",\n",
    "    \"Dear subscriber, your mobile number has won 1st prize of Rs.25 Lakh. Contact lottery helpdesk: lottery-india.com\",\n",
    "    \"Amazon Great Indian Festival: You won a Samsung Galaxy S24. Claim by paying Rs.250 delivery charge: amzn-prize.in\",\n",
    "    \"Paytm: You have been selected for a scratch card prize of Rs.5000. Click to claim: paytm-reward24.net\",\n",
    "    \"Your phone number won Rs.2,50,000 in BSNL's 25th anniversary draw. Contact us within 72 hours: bsnl-lottery.org\",\n",
    "    \"Spin the wheel! You have won a free trip to Dubai. To confirm your booking pay Rs.500: travelwin.site\",\n",
    "    \"You are the 1,000,000th visitor! Claim your prize of Rs.1 Lakh. Enter details at: bigwin-india.net\",\n",
    "\n",
    "    # --- OTP Scams ---\n",
    "    \"Your Paytm account will be blocked. Share OTP received on your mobile to KYC executive to avoid suspension.\",\n",
    "    \"SBI: We are verifying your account. An OTP will be sent. Please share it with our executive immediately.\",\n",
    "    \"URGENT: Your UPI is being compromised. Call 9876543210 and share the OTP you receive to secure your account.\",\n",
    "    \"Phonepe Security: Your account has suspicious activity. Share OTP with helpdesk to freeze attacker's access.\",\n",
    "    \"HDFC: Our security team detected a login from unknown device. Share your OTP with us to block this access.\",\n",
    "    \"Amazon: Your order is fraudulently placed. Share OTP to cancel and get refund. Call: 8877665544\",\n",
    "    \"Google Pay: To secure your wallet, share the 6-digit code sent to your registered mobile with our agent.\",\n",
    "    \"Your account is being hacked right now. Call immediately and share any OTP you receive: 9001122334\",\n",
    "    \"IRCTC: Your ticket booking requires OTP verification. Share OTP with agent on 8899002211 to confirm.\",\n",
    "    \"Flipkart: Refund of Rs.2,499 is being processed. Share OTP to receive money directly in your account.\",\n",
    "\n",
    "    # --- Additional Mixed Scams ---\n",
    "    \"You have pending UPI payment of Rs.15,000. Collect it by clicking: upi-collect.site/claim\",\n",
    "    \"Income Tax Dept: You have a pending tax refund of Rs.8,450. Claim at: incometax-refund.net\",\n",
    "    \"Your Aadhaar card is linked to illegal activities. Call 1800-111-2233 immediately or face arrest.\",\n",
    "    \"TRAI will block your SIM in 2 hours due to illegal usage. Call 9988001122 to avoid disconnection.\",\n",
    "    \"FREE COVID-19 insurance worth Rs.5 Lakh. Register at: gov-covid-coverage.net. Limited offer!\",\n",
    "    \"PM Kisan Yojana: Rs.6000 pending in your account. Update bank details at: pmkisan-update.in\",\n",
    "    \"EPF withdrawal: Your PF amount of Rs.48,000 is ready. Share OTP and bank details to receive.\",\n",
    "    \"Mutual fund investment opportunity: 40% return in 3 months. Guaranteed! Invest now: mfinvest24.com\",\n",
    "    \"Electricity bill overdue. Pay Rs.1,890 in 24 hours or connection will be cut: bescom-pay.xyz\",\n",
    "    \"Gas connection: Your cylinder booking failed. Pay Rs.50 processing fee here: hpcl-book.net\",\n",
    "    \"Airtel SIM upgrade required. To avoid signal loss, confirm your details at: airtel-upgrade.site\",\n",
    "    \"Vi (Vodafone Idea): Your plan expires today. Recharge Rs.299 to avoid suspension: vi-recharge.net\",\n",
    "    \"BEED: Get Rs.10,000 daily from crypto trading! Join our Telegram group: t.me/cryptoprofit2024\",\n",
    "    \"Loan approved! Get Rs.5 Lakh in 10 minutes. No documents. Just pay Rs.1000 processing fee: loanfast.in\",\n",
    "    \"Personal loan at 0% interest. Limited time offer. Apply now: instacashloan.site\",\n",
    "    \"Your car insurance expired. Renew now at 50% discount before 24hrs: carinsure-renew.net\",\n",
    "    \"Jio GigaFiber: Free upgrade to 1 Gbps. Technician will visit. Confirm at: jio-upgrade.xyz\",\n",
    "    \"TATA Play: Your DTH subscription expires in 24 hours. Recharge at: tataplay-offer.site\",\n",
    "    \"WhatsApp is expiring on your number. Pay Rs.99 to continue: wa-renew.site\",\n",
    "    \"Your Google account has been compromised. Verify identity at: google-verify.security-check.site\",\n",
    "    \"Truecaller Premium: You have been selected for a free 1-year subscription. Claim: tc-premium.in\",\n",
    "    \"NPCI: Unified Payment Interface error detected. Verify your UPI PIN at: npci-verify.net\",\n",
    "    \"CSC Center: You are eligible for free laptop under government scheme. Register: csc-laptop.in\",\n",
    "    \"Dating app match! Click to see who liked you: datingapp-match.site (18+ only)\",\n",
    "    \"Earn Rs.1000 per day by watching YouTube videos. No skills needed. Join: ytearning.in\",\n",
    "    \"Your Swiggy/Zomato order was cancelled. Rs.200 refund pending. Verify bank details: swiggy-refund.net\",\n",
    "    \"Meesho: You have unclaimed cashback of Rs.320. Collect by updating payment info at: meesho-cashback.in\",\n",
    "    \"HDFC Credit Card: Rs.4,999 cashback is pending. Verify card details to receive: hdfc-cashback.site\",\n",
    "    \"Your PAN card is linked to money laundering case. Contact CBI helpline immediately: 9900110022\",\n",
    "    \"Customs seized your international package. Pay Rs.3,500 clearance fee: customs-clearance.in\",\n",
    "    \"Army canteen job vacancy. Salary Rs.35,000. Apply by sending Rs.500 registration fee to 9876543210\",\n",
    "    \"Railway recruitment: 5000 vacancies. Apply now. Registration fee Rs.300: railway-apply24.com\",\n",
    "    \"UPSC coaching scholarship! Win Rs.50,000. Last date today. Register: scholarship-upsc.in\",\n",
    "    \"IIT student investment club: Turn Rs.5,000 into Rs.50,000 in a month using AI trading bot.\",\n",
    "    \"Medical emergency! Your relative is in hospital. Pay Rs.15,000 immediately. Call 9988112233.\",\n",
    "    \"Lucky SIM draw: Your number +91-XXXXX has won Rs.30 Lakh. Contact: prize@lottery-india.org\",\n",
    "    \"Agent: Hi I am calling from SBI credit card team. Please share your card number and CVV for an upgrade.\",\n",
    "    \"Congratulations! You are selected for Shark Tank India investment program. Invest Rs.2000 to proceed.\",\n",
    "    \"Earn money using crypto P2P: Deposit Rs.2,000, get Rs.6,000 back in 24 hours. Telegram: @p2pearner\",\n",
    "    \"Sponsored Task App: Complete simple tasks online. Earn Rs.500-Rs.5000 daily. Download: taskearner.apk\",\n",
    "    \"Your home loan EMI payment failed. Pay immediately or legal action will be taken: homeloan-emi.site\",\n",
    "    \"NPS (National Pension Scheme): Your pension fund of Rs.1.2 Lakh is unclaimed. Claim: nps-claim.in\",\n",
    "    \"Immediate action required: IT department freeze on account due to tax evasion. Pay Rs.5,000 fine online.\",\n",
    "    \"Free Jio SIM upgrade to 5G. Technician visit tomorrow. Confirm address: jio5g-upgrade.net\",\n",
    "    \"Win a brand new Royal Enfield Bullet! Participate in lucky draw. Register: motorcyclewin.in\",\n",
    "    \"Binance India: Your crypto wallet has Rs.12,500 bonus. Withdraw at: binance-india-withdraw.site\",\n",
    "    \"Your Netflix subscription will auto-renew for Rs.1499. To cancel, click: netflix-cancel.net\",\n",
    "    \"HDFC Bank: Suspicious transaction of Rs.49,999 detected. Call 1800-xxx-xxxx to block immediately.\",\n",
    "]\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'text': synthetic_scams,\n",
    "    'label': [1] * len(synthetic_scams)\n",
    "})\n",
    "\n",
    "print(f'‚úÖ Synthetic dataset generated: {len(df3)} scam messages')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-08",
   "metadata": {},
   "source": [
    "## Step 7 ‚Äî Merge & Clean All Datasets\n",
    "\n",
    "We now combine all three datasets into one DataFrame and apply basic cleaning:\n",
    "\n",
    "1. **Lowercase** ‚Äî models are less confused by consistent casing\n",
    "2. **Remove extra whitespace** ‚Äî trim leading/trailing spaces and collapse multiple spaces\n",
    "3. **Drop empty rows** ‚Äî remove any rows with missing or empty text\n",
    "4. **Deduplicate** ‚Äî remove exact duplicate messages\n",
    "5. **Token limit** ‚Äî we'll truncate at 256 tokens during tokenization (handled later)\n",
    "\n",
    "We also display the final class distribution to understand the dataset balance."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all three datasets\n",
    "df_all = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()              # lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)      # collapse whitespace\n",
    "    text = text.strip()                   # strip leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "df_all['text'] = df_all['text'].apply(clean_text)\n",
    "\n",
    "# Drop empty and duplicate rows\n",
    "df_all = df_all[df_all['text'].str.len() > 5]   # remove very short / empty\n",
    "df_all = df_all.drop_duplicates(subset='text')   # remove exact duplicates\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "# Ensure label is int\n",
    "df_all['label'] = df_all['label'].astype(int)\n",
    "\n",
    "print(f'‚úÖ Merged dataset: {len(df_all)} total messages')\n",
    "print(f'   Safe (0): {(df_all.label == 0).sum()} | Scam (1): {(df_all.label == 1).sum()}')\n",
    "\n",
    "# Plot class distribution\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "counts = df_all['label'].value_counts().sort_index()\n",
    "bars = ax.bar(['Safe (0)', 'Scam (1)'], counts.values, color=['#2196F3', '#F44336'], edgecolor='white', linewidth=1.5)\n",
    "for bar, count in zip(bars, counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 30, str(count), ha='center', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Dataset Class Distribution', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Number of Messages')\n",
    "ax.set_ylim(0, max(counts.values) * 1.15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nSample messages:')\n",
    "df_all.groupby('label').head(2)"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-09",
   "metadata": {},
   "source": [
    "## Step 8 ‚Äî Train / Validation / Test Split\n",
    "\n",
    "We split our data into three sets:\n",
    "\n",
    "| Set | Size | Purpose |\n",
    "|-----|------|---------|\n",
    "| **Train** | 80% | Model learns from this data |\n",
    "| **Validation** | 10% | Monitor performance during training to avoid overfitting |\n",
    "| **Test** | 10% | Final evaluation on unseen data |\n",
    "\n",
    "We use `stratify=label` to keep the same ham/spam ratio in each split."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 80% train, 20% temp\n",
    "df_train, df_temp = train_test_split(\n",
    "    df_all, test_size=0.20, random_state=42, stratify=df_all['label']\n",
    ")\n",
    "\n",
    "# Second split: temp ‚Üí 50% val, 50% test (each = 10% of total)\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp, test_size=0.50, random_state=42, stratify=df_temp['label']\n",
    ")\n",
    "\n",
    "print(f'‚úÖ Train:      {len(df_train)} samples')\n",
    "print(f'   Validation: {len(df_val)} samples')\n",
    "print(f'   Test:       {len(df_test)} samples')\n",
    "print(f'\\nTrain label distribution:\\n{df_train[\"label\"].value_counts().to_string()}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-10",
   "metadata": {},
   "source": [
    "## Step 9 ‚Äî Tokenization\n",
    "\n",
    "Transformers don't work with raw text ‚Äî they need numbers. A **tokenizer** converts text into tokens (word pieces) and maps them to numeric IDs.\n",
    "\n",
    "We use `distilbert-base-uncased`:\n",
    "- `uncased` means it treats `HELLO` and `hello` as the same\n",
    "- `max_length=256` ‚Äî we truncate/pad to 256 tokens (SMS messages are short, so very few will exceed this)\n",
    "\n",
    "The tokenizer also adds special tokens:\n",
    "- `[CLS]` ‚Äî placed at the start; the model uses this to classify the whole message\n",
    "- `[SEP]` ‚Äî marks the end of the text"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Convert DataFrames to HuggingFace Dataset objects\n",
    "train_ds = Dataset.from_pandas(df_train[['text', 'label']].reset_index(drop=True))\n",
    "val_ds   = Dataset.from_pandas(df_val[['text', 'label']].reset_index(drop=True))\n",
    "test_ds  = Dataset.from_pandas(df_test[['text', 'label']].reset_index(drop=True))\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "# Apply tokenization\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True)\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "# Rename label column to 'labels' (what HuggingFace Trainer expects)\n",
    "train_ds = train_ds.rename_column('label', 'labels')\n",
    "val_ds   = val_ds.rename_column('label', 'labels')\n",
    "test_ds  = test_ds.rename_column('label', 'labels')\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "print(f'‚úÖ Tokenization complete!')\n",
    "print(f'   Training samples: {len(train_ds)}')\n",
    "print(f'   A sample token IDs (first 10): {train_ds[0][\"input_ids\"][:10].tolist()}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-11",
   "metadata": {},
   "source": [
    "## Step 10 ‚Äî Load DistilBERT Model\n",
    "\n",
    "We load `DistilBertForSequenceClassification` ‚Äî a DistilBERT model with a **classification head** on top.\n",
    "\n",
    "The classification head is a small neural network added after DistilBERT's transformer layers. It takes the `[CLS]` token representation and outputs 2 scores (one per class: safe / scam).\n",
    "\n",
    "Setting `num_labels=2` tells the model we have a binary classification problem."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    id2label={0: 'SAFE', 1: 'SCAM'},\n",
    "    label2id={'SAFE': 0, 'SCAM': 1},\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'‚úÖ Model loaded: {MODEL_NAME}')\n",
    "print(f'   Total parameters:     {total_params:,}')\n",
    "print(f'   Trainable parameters: {trainable_params:,}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-12",
   "metadata": {},
   "source": [
    "## Step 11 ‚Äî Define Evaluation Metrics\n",
    "\n",
    "We define a `compute_metrics` function that the Trainer will call at the end of each epoch to evaluate model performance on the validation set.\n",
    "\n",
    "We track:\n",
    "- **Accuracy** ‚Äî overall correctness\n",
    "- **F1 Score** ‚Äî weighted average of precision and recall (handles class imbalance well)"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load('accuracy')\n",
    "f1_metric       = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    f1  = f1_metric.compute(predictions=predictions, references=labels, average='weighted')['f1']\n",
    "    return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "# Data collator: handles padding within each batch dynamically (more efficient than static padding)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "print('‚úÖ Metrics and data collator ready')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-13",
   "metadata": {},
   "source": [
    "## Step 12 ‚Äî Training Configuration\n",
    "\n",
    "We configure the training hyperparameters:\n",
    "\n",
    "| Hyperparameter | Value | Why |\n",
    "|---|---|---|\n",
    "| **Epochs** | 3 | Enough to converge without overfitting |\n",
    "| **Batch size** | 16 | Standard for fine-tuning on a T4 GPU |\n",
    "| **Learning rate** | 2e-5 | Low enough to preserve pre-trained weights |\n",
    "| **Weight decay** | 0.01 | Regularization to prevent overfitting |\n",
    "| **Warmup** | 10% of steps | Gradually ramps LR up to prevent early instability |\n",
    "\n",
    "The **Trainer** API handles the training loop, validation, and checkpointing automatically."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = '/content/drive/MyDrive/scamshield-distilbert'\n",
    "OUTPUT_DIR = '/content/scamshield-checkpoints'\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "total_steps = (len(train_ds) // BATCH_SIZE) * NUM_EPOCHS\n",
    "warmup_steps = int(0.10 * total_steps)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_dir='/content/logs',\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),   # faster training on GPU with 16-bit floats\n",
    "    report_to='none',                 # disable WandB / HuggingFace Hub logging\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(f'‚úÖ Trainer configured')\n",
    "print(f'   Total training steps: {total_steps}')\n",
    "print(f'   Warmup steps: {warmup_steps}')\n",
    "print(f'   Model will be saved to: {SAVE_PATH}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-14",
   "metadata": {},
   "source": [
    "## Step 13 ‚Äî Fine-Tune the Model üöÄ\n",
    "\n",
    "Now we start training! The model will:\n",
    "\n",
    "1. Pass each batch of messages through DistilBERT\n",
    "2. Compare predictions to the true labels using **cross-entropy loss**\n",
    "3. Use **backpropagation + Adam optimizer** to update weights\n",
    "4. Repeat for 3 epochs\n",
    "\n",
    "At the end of each epoch, it evaluates on the **validation set** and saves the best checkpoint.\n",
    "\n",
    "> ‚è±Ô∏è Expected training time on T4 GPU: **~8‚Äì15 minutes**"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üöÄ Starting fine-tuning...')\n",
    "train_result = trainer.train()\n",
    "\n",
    "print('\\n‚úÖ Training complete!')\n",
    "print(f'   Final training loss: {train_result.training_loss:.4f}')\n",
    "print(f'   Total training time: {train_result.metrics[\"train_runtime\"]:.1f}s')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-15",
   "metadata": {},
   "source": [
    "## Step 14 ‚Äî Evaluate on Test Set\n",
    "\n",
    "We run the final evaluation on the **test set** ‚Äî data the model has never seen during training or validation.\n",
    "\n",
    "We compute:\n",
    "- **Accuracy, Precision, Recall, F1** using `sklearn.metrics.classification_report`\n",
    "- **Confusion Matrix** as a visual heatmap\n",
    "\n",
    "### Reading the Confusion Matrix\n",
    "\n",
    "```\n",
    "               Predicted Safe   Predicted Scam\n",
    "Actual Safe    [ True Neg  ]    [ False Pos ]\n",
    "Actual Scam    [ False Neg ]    [ True  Pos ]\n",
    "```\n",
    "\n",
    "- **False Negatives** (Scam predicted as Safe) are the most dangerous ‚Äî missed scams!\n",
    "- **False Positives** (Safe predicted as Scam) are annoying but safer."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üìä Evaluating on test set...')\n",
    "predictions_output = trainer.predict(test_ds)\n",
    "y_pred = np.argmax(predictions_output.predictions, axis=-1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "print('\\n--- Classification Report ---')\n",
    "print(classification_report(y_true, y_pred, target_names=['Safe (0)', 'Scam (1)']))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Predicted Safe', 'Predicted Scam'],\n",
    "    yticklabels=['Actual Safe', 'Actual Scam'],\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title('Confusion Matrix ‚Äî ScamShield DistilBERT', fontsize=13, fontweight='bold', pad=12)\n",
    "ax.set_ylabel('True Label', fontsize=11)\n",
    "ax.set_xlabel('Predicted Label', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(f'\\nüìå Summary Metrics:')\n",
    "print(f'   Accuracy:  {accuracy_score(y_true, y_pred):.4f}')\n",
    "print(f'   Precision: {precision_score(y_true, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'   Recall:    {recall_score(y_true, y_pred, average=\"weighted\"):.4f}')\n",
    "print(f'   F1 Score:  {f1_score(y_true, y_pred, average=\"weighted\"):.4f}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-16",
   "metadata": {},
   "source": [
    "## Step 15 ‚Äî Quick Demo: Classify Custom Messages\n",
    "\n",
    "Let's test the model with a few custom messages to see it in action before saving!"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_message(text, model, tokenizer, threshold=0.5):\n",
    "    \"\"\"Classify a single message as SAFE or SCAM.\"\"\"\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=MAX_LENGTH)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=-1)[0]\n",
    "    label = 'SCAM üö®' if probs[1].item() >= threshold else 'SAFE ‚úÖ'\n",
    "    return label, probs[0].item(), probs[1].item()\n",
    "\n",
    "test_messages = [\n",
    "    \"Hey, are you free to meet for lunch tomorrow at 1pm?\",\n",
    "    \"Your SBI account will be suspended. Update KYC immediately at http://sbi-kyc.xyz\",\n",
    "    \"Congratulations! You won Rs.50 Lakh in KBC Lucky Draw. Call 9876543210 to claim.\",\n",
    "    \"Reminder: Your doctor appointment is scheduled for 3pm on Monday.\",\n",
    "    \"URGENT: Your Aadhaar is linked to illegal activities. Call 1800-111-2233 or face arrest.\",\n",
    "    \"Mom said she will be home by 7pm. Don't forget to pick up milk on the way.\",\n",
    "]\n",
    "\n",
    "print('=== ScamShield Classifier Demo ===')\n",
    "for msg in test_messages:\n",
    "    label, safe_prob, scam_prob = predict_message(msg, model, tokenizer)\n",
    "    display_msg = msg[:70] + '...' if len(msg) > 70 else msg\n",
    "    print(f'\\nMessage: \"{display_msg}\"')\n",
    "    print(f'Result:  {label} | Safe: {safe_prob:.2%} | Scam: {scam_prob:.2%}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-17",
   "metadata": {},
   "source": [
    "## Step 16 ‚Äî Save Model & Tokenizer to Google Drive üíæ\n",
    "\n",
    "We save both the trained model weights and the tokenizer to your Google Drive.\n",
    "This way, you can:\n",
    "- Download the model and use it in the ScamShield backend\n",
    "- Load it later for inference without retraining\n",
    "\n",
    "The saved folder will contain:\n",
    "```\n",
    "scamshield-distilbert/\n",
    "‚îú‚îÄ‚îÄ config.json           ‚Üê model architecture config\n",
    "‚îú‚îÄ‚îÄ model.safetensors     ‚Üê trained weights\n",
    "‚îú‚îÄ‚îÄ tokenizer_config.json ‚Üê tokenizer settings\n",
    "‚îú‚îÄ‚îÄ tokenizer.json        ‚Üê vocab and rules\n",
    "‚îî‚îÄ‚îÄ vocab.txt             ‚Üê vocabulary\n",
    "```\n",
    "\n",
    "To load later:\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./scamshield-distilbert')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./scamshield-distilbert')\n",
    "```"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-code-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "\n",
    "saved_files = os.listdir(SAVE_PATH)\n",
    "print(f'‚úÖ Model saved to: {SAVE_PATH}')\n",
    "print(f'   Files: {saved_files}')\n",
    "\n",
    "# Also save training info\n",
    "import json\n",
    "training_info = {\n",
    "    'model': MODEL_NAME,\n",
    "    'num_labels': 2,\n",
    "    'label_mapping': {'0': 'SAFE', '1': 'SCAM'},\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'dataset_sizes': {\n",
    "        'total': len(df_all),\n",
    "        'train': len(df_train),\n",
    "        'val': len(df_val),\n",
    "        'test': len(df_test),\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'accuracy': float(accuracy_score(y_true, y_pred)),\n",
    "        'f1_weighted': float(f1_score(y_true, y_pred, average='weighted')),\n",
    "        'precision_weighted': float(precision_score(y_true, y_pred, average='weighted')),\n",
    "        'recall_weighted': float(recall_score(y_true, y_pred, average='weighted')),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(SAVE_PATH, 'training_info.json'), 'w') as f:\n",
    "    json.dump(training_info, f, indent=2)\n",
    "\n",
    "print('\\nüìã Training info saved to training_info.json')\n",
    "print(json.dumps(training_info, indent=2))"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "cell-md-18",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "Congratulations! You have successfully fine-tuned DistilBERT for scam detection.\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Download the model:**\n",
    "```python\n",
    "from google.colab import files\n",
    "import shutil\n",
    "shutil.make_archive('scamshield-distilbert', 'zip', '/content/drive/MyDrive/scamshield-distilbert')\n",
    "files.download('scamshield-distilbert.zip')\n",
    "```\n",
    "\n",
    "**Use in ScamShield backend:**\n",
    "```python\n",
    "from transformers import pipeline\n",
    "classifier = pipeline('text-classification', model='./scamshield-distilbert')\n",
    "result = classifier('Your account will be blocked. Update KYC at http://fake.site')\n",
    "print(result)  # [{'label': 'SCAM', 'score': 0.9987}]\n",
    "```\n",
    "\n",
    "**Retrain on new data:** Add new messages to Step 6 (Synthetic Data) and re-run all cells.\n",
    "\n",
    "---\n",
    "\n",
    "> Built with ‚ù§Ô∏è for [ScamShield](https://github.com/thepriyanshumishra/scamshield-web)"
   ]
  }

 ]
}
